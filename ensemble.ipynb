{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/Engineer-Ayesha-Shafique/Brain-Tumor-Segmentation-and-Detection-using-UNET-and-Watershed-in-Python/blob/main/Brain_Tumor_Segmentation_and_Detection_using_UNET_and_Watershed_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v0LHr_cN94aF","outputId":"cf896ec6-4d66-46ed-8076-c495b0fc99fb","executionInfo":{"status":"ok","timestamp":1745647006997,"user_tz":-180,"elapsed":2852,"user":{"displayName":"Abdlrahman Kobaissy","userId":"02284448119242242699"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive' ,force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"Yacw50PTTLCQ"},"source":["#MOE\n","\n","\n"]},{"cell_type":"code","source":["import os\n","BASE_MODEL_PATH = \"/content/drive/MyDrive/Project_41725\"\n","MODEL_1 = os.path.join(BASE_MODEL_PATH, \"files\" , \"UNetModified\" , \"model.h5\")\n","MODEL_2 = os.path.join(BASE_MODEL_PATH, \"files\" , \"LinkNet\" , \"model.h5\")\n","MODEL_3 = os.path.join(BASE_MODEL_PATH, \"files\", \"aug_pass\" , \"model_512.h5\")\n","MODEL_4 = os.path.join(BASE_MODEL_PATH, \"files\", \"DG\" , \"model.h5\")\n","MODEL_5 = os.path.join(BASE_MODEL_PATH, \"files\", \"DG\" , \"model_256.h5\")"],"metadata":{"id":"8aJ2oKaYnd1M","executionInfo":{"status":"ok","timestamp":1745647007029,"user_tz":-180,"elapsed":9,"user":{"displayName":"Abdlrahman Kobaissy","userId":"02284448119242242699"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    for gpu in gpus:\n","        tf.config.experimental.set_memory_growth(gpu, True)\n","    print(f\"âœ… TensorFlow will use {len(gpus)} GPU(s)\")\n","else:\n","    print(\"âš ï¸ No GPU detected for TensorFlow\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wNQiO38M8v-4","executionInfo":{"status":"ok","timestamp":1745647011477,"user_tz":-180,"elapsed":4446,"user":{"displayName":"Abdlrahman Kobaissy","userId":"02284448119242242699"}},"outputId":"a26b59a0-ea99-42f1-e482-d8d439c82dd3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… TensorFlow will use 1 GPU(s)\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, KFold\n","from xgboost import XGBClassifier\n","from tqdm import tqdm\n","import imageio"],"metadata":{"id":"1ixsseaB8uIZ","executionInfo":{"status":"ok","timestamp":1745647011962,"user_tz":-180,"elapsed":486,"user":{"displayName":"Abdlrahman Kobaissy","userId":"02284448119242242699"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# â”€â”€ 1) Imports & constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","import os\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n","\n","import tensorflow as tf\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import (\n","    Input, Conv2D, Activation, Lambda\n",")\n","\n","INPUT_SHAPE = (224, 224, 3)\n","NUM_CLASSES = 5"],"metadata":{"id":"jwPlOqg0q_bu","executionInfo":{"status":"ok","timestamp":1745647012030,"user_tz":-180,"elapsed":67,"user":{"displayName":"Abdlrahman Kobaissy","userId":"02284448119242242699"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!pip install --quiet segmentation-models tensorflow-addons\n"],"metadata":{"id":"VHzsjqsR5HMl","executionInfo":{"status":"ok","timestamp":1745647015841,"user_tz":-180,"elapsed":3797,"user":{"displayName":"Abdlrahman Kobaissy","userId":"02284448119242242699"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c759a773-d143-42d7-8c12-dfe9ea72ee2b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/611.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/50.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import os\n","os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n","\n","import segmentation_models as sm\n","from tensorflow.keras import Model, Input\n","from tensorflow.keras.layers import (\n","    Conv2D, BatchNormalization, Activation,\n","    MaxPool2D\n",")\n","from tensorflow.keras.applications import EfficientNetB4\n","\n","sm.set_framework('tf.keras')\n","\n","BASE_MODEL_PATH = \"/content/drive/MyDrive/Project_41725\"\n","MODEL_1_UNet = os.path.join(BASE_MODEL_PATH, \"files\" , \"UNetModified\" , \"model.h5\")\n","MODEL_2_LINKNET = os.path.join(BASE_MODEL_PATH, \"files\" ,\"LinkNet\", \"modell.h5\")\n","MODEL_3_AttentionUNet = os.path.join(BASE_MODEL_PATH, \"files\", \"aug_pass\", \"model_512.h5\")\n","MODEL_4_DGNet = MODEL_4\n","MODEL_5_Upp =  MODEL_5\n","INPUT_SHAPE = (512, 512, 3)\n","ds_path = \"/content/drive/MyDrive/Project_41725/newdata/train_maskimg\"\n","mask_dir = \"/content/drive/MyDrive/Project_41725/newdata/train_maskimg/masks\"\n"],"metadata":{"id":"rQpQpgEf1BWw","executionInfo":{"status":"ok","timestamp":1745647015993,"user_tz":-180,"elapsed":149,"user":{"displayName":"Abdlrahman Kobaissy","userId":"02284448119242242699"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9351b943-5a64-4755-af9a-0f2abfd9628e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Segmentation Models: using `tf.keras` framework.\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"sTVIxx_sD755","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745647027610,"user_tz":-180,"elapsed":11616,"user":{"displayName":"Abdlrahman Kobaissy","userId":"02284448119242242699"}},"outputId":"c4d52db8-2803-476b-c2cf-1637b1346fad"},"outputs":[{"output_type":"stream","name":"stdout","text":["[GPU] Detected 1 GPU(s).\n","Train: 1216, Val: 348, Test: 174\n"]}],"source":["# In a notebook cell, before any cv2 imports:\n","!pip install --quiet opencv-python-headless\n","import os\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n","\n","# 1) Import TF first and set memory growth (fallback to experimental)\n","import tensorflow as tf\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    for gpu in gpus:\n","        try:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        except Exception as e:\n","            print(f\"[GPU] Could not set memory growth: {e}\")\n","    print(f\"[GPU] Detected {len(gpus)} GPU(s).\")\n","\n","# 2) Now import the rest\n","import numpy as np\n","import cv2\n","from glob import glob\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import (\n","    ModelCheckpoint, CSVLogger, ReduceLROnPlateau,\n","    EarlyStopping, TensorBoard\n",")\n","from tensorflow.keras.optimizers import Adam\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, KFold\n","from xgboost import XGBClassifier\n","from tqdm import tqdm\n","import imageio\n","\"\"\" Global parameters \"\"\"\n","Height = 512\n","Width  = 512\n","\n","def create_folder(path):\n","    if not os.path.exists(path):\n","        os.makedirs(path)\n","\n","def load_dataset(path_dataset, val_ratio=0.2, test_ratio=0.1, random_state=42):\n","    img_dir  = os.path.join(path_dataset, \"images\")\n","    mask_dir = os.path.join(path_dataset, \"masks\")\n","\n","    image_exts = ('.png', '.jpg', '.jpeg')\n","    images = sorted([\n","        os.path.join(img_dir, f)\n","        for f in os.listdir(img_dir)\n","        if f.lower().endswith(image_exts)\n","    ])\n","\n","\n","    mask_exts = ('.tif', '.tiff')\n","    masks = sorted([\n","        os.path.join(mask_dir, f)\n","        for f in os.listdir(mask_dir)\n","        if f.lower().endswith(mask_exts)\n","    ])\n","\n","    if not images:\n","        raise RuntimeError(f\"No images found in {img_dir}\")\n","    if not masks:\n","        raise RuntimeError(f\"No masks found in {mask_dir}\")\n","\n","    images_lookup = {\n","        os.path.splitext(os.path.basename(p))[0]: p\n","        for p in images\n","    }\n","#MildDemented_0a7b1321-eba0-40dc-85b8-de34241554a2_jpg.rf.70370fcd9ac0fb82f91d27f558053d84.tif\n","    pairs = []\n","    for m in masks:\n","        base = os.path.splitext(os.path.basename(m))[0]\n","        if base.endswith('_mask'):\n","            root = base[:-5]\n","            img_path = images_lookup.get(root)\n","            if img_path:\n","                pairs.append((img_path, m))\n","\n","    if not pairs:\n","        raise RuntimeError(\"No matching imageâ†”mask pairs found!\")\n","\n","    trainval, test = train_test_split(pairs, test_size=test_ratio, random_state=random_state)\n","    val_frac = val_ratio / (1.0 - test_ratio)\n","    train, val = train_test_split(trainval, test_size=val_frac, random_state=random_state)\n","\n","    train_imgs, train_masks = zip(*train)\n","    val_imgs,   val_masks   = zip(*val)\n","    test_imgs,  test_masks  = zip(*test)\n","\n","    return (\n","        list(train_imgs), list(train_masks),\n","        list(val_imgs),   list(val_masks),\n","        list(test_imgs),  list(test_masks)\n","    )\n","\n","def read_image_file(path_img):\n","    path = path_img.decode('utf-8') if isinstance(path_img, bytes) else path_img\n","    img = cv2.imread(path, cv2.IMREAD_COLOR)\n","    img = cv2.resize(img, (Width, Height)) / 255.0\n","    return img.astype(np.float32)\n","\n","def read_mask_file(path_mask):\n","    path = path_mask.decode('utf-8') if isinstance(path_mask, bytes) else path_mask\n","    mask = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n","    if mask.ndim == 3:\n","        mask = mask[..., 0]\n","    mask = cv2.resize(mask, (Width, Height), interpolation=cv2.INTER_NEAREST)\n","\n","    # âœ… Clip to [0, 4], not [0, 3]:\n","    mask = np.clip(mask, 0, NUM_CLASSES-1)\n","\n","    # Convert to integer class IDs\n","    mask = mask.astype(np.int32)\n","\n","    # Add the channel dim back\n","    return mask[..., None]\n","\n","def tf_parse(path_img, path_mask):\n","    # Tell numpy_function: imgâ†’float32, maskâ†’int32\n","    img, mask = tf.numpy_function(\n","        lambda pi, pm: (read_image_file(pi), read_mask_file(pm)),\n","        [path_img, path_mask],\n","        [tf.float32, tf.int32]          # <-- second output is now int32\n","    )\n","    img.set_shape([Height, Width, 3])\n","    mask.set_shape([Height, Width, 1])\n","    return img, mask\n","\n","def tf_dataset(inputs, targets, batch_size=2):\n","    ds = tf.data.Dataset.from_tensor_slices((inputs, targets))\n","    ds = ds.map(tf_parse, num_parallel_calls=tf.data.AUTOTUNE)\n","    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","    return ds\n","\n","def edit_mask_images(mask_dir, func, output_dir=None):\n","    out_dir = output_dir or mask_dir\n","    create_folder(out_dir)\n","    exts = ('.tif')\n","    for fname in os.listdir(mask_dir):\n","        if not fname.lower().endswith(exts):\n","            continue\n","        in_path  = os.path.join(mask_dir, fname)\n","        mask     = cv2.imread(in_path, cv2.IMREAD_UNCHANGED)\n","        edited   = func(mask)\n","        cv2.imwrite(os.path.join(out_dir, fname), edited)\n","    print(f\"[edit_mask_images] Applied edits to masks in {out_dir}\")\n","\n","if __name__ == \"__main__\":\n","    np.random.seed(42)\n","    tf.random.set_seed(42)\n","\n","    create_folder(\"/content/drive/MyDrive/Project_41725/files\")\n","\n","    batch_size = 16\n","    lr         = 1e-4\n","    epochs_num     = 100\n","    path_model = os.path.join(\"/content/drive/MyDrive/Project_41725/files\", \"model.h5\")\n","    path_csv   = os.path.join(\"/content/drive/MyDrive/Project_41725/files\", \"log.csv\")\n","\n","    ds_path = \"/content/drive/MyDrive/Project_41725/newdata/train_maskimg\"\n","    train_imgs, train_masks, val_imgs, val_masks, test_imgs, test_masks = load_dataset(ds_path)\n","\n","    print(f\"Train: {len(train_imgs)}, Val: {len(val_imgs)}, Test: {len(test_imgs)}\")\n","\n","    train_ds = tf_dataset(train_imgs, train_masks, batch_size=batch_size)\n","    val_ds   = tf_dataset(val_imgs,   val_masks,   batch_size=batch_size)\n","    test_ds  = tf_dataset(test_imgs,  test_masks,  batch_size=batch_size)\n","\n","    # Build, compile and fit your model below:\n","    # model = Unet_model((Height, Width, 3))\n","    # model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coeff])\n","    # callbacks = [ModelCheckpoint(...), ...]\n","    # model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=callbacks)\n"]},{"cell_type":"code","source":["import pandas as pd\n","\n","# assuming youâ€™ve re-run the load_dataset cell in XGBoost_ensemble.ipynb\n","# so train_imgs, train_masks, test_imgs are available:\n","\n","pd.DataFrame({'image_path': train_imgs}).to_csv('train_images.csv', index=False)\n","pd.DataFrame({'mask_path':  train_masks}).to_csv('train_masks.csv',  index=False)\n","pd.DataFrame({'image_path': test_imgs }).to_csv('test_images.csv',  index=False)\n","print(\"Manifest CSVs written.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"REl8w4qgr0Ur","executionInfo":{"status":"ok","timestamp":1745647027658,"user_tz":-180,"elapsed":45,"user":{"displayName":"Abdlrahman Kobaissy","userId":"02284448119242242699"}},"outputId":"b5d52aac-3924-43ee-f2e3-98faf4398638"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Manifest CSVs written.\n"]}]},{"cell_type":"code","execution_count":11,"metadata":{"id":"NMrqwAWO8VHo","executionInfo":{"status":"ok","timestamp":1745647027828,"user_tz":-180,"elapsed":168,"user":{"displayName":"Abdlrahman Kobaissy","userId":"02284448119242242699"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import (\n","    ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",")\n","import os\n","# Make sure segmentation_models picks up tf.keras, not plain keras\n","os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.utils import get_custom_objects\n","import segmentation_models as sm\n","\n","# Hyperâ€‘params & paths\n","NUM_CLASSES = 5\n","INPUT_SHAPE = (512, 512, 3)\n","EPOCHS      = 160\n","path_model  = \"/content/drive/MyDrive/Project_41725/XGBoost/files/model.h5\"\n","path_csv    = \"/content/drive/MyDrive/Project_41725/XGBoost/files/log.csv\"\n","\n","# 0) kill any existing graph/state\n","tf.keras.backend.clear_session()\n","\n","# 3) Define losses & metrics\n","def dice_coef(y_true, y_pred, smooth=1e-6):\n","    y_true = tf.squeeze(y_true, axis=-1)\n","    y_true_o = tf.one_hot(tf.cast(y_true, tf.int32), depth=NUM_CLASSES)\n","    y_true_f = tf.reshape(y_true_o, [-1, NUM_CLASSES])\n","    y_pred_f = tf.reshape(y_pred,   [-1, NUM_CLASSES])\n","    inter = tf.reduce_sum(y_true_f * y_pred_f, axis=0)\n","    denom = tf.reduce_sum(y_true_f, axis=0) + tf.reduce_sum(y_pred_f, axis=0)\n","    dice_per_class = (2. * inter + smooth) / (denom + smooth)\n","    return tf.reduce_mean(dice_per_class)\n","\n","def dice_loss(y_true, y_pred):\n","    return 1.0 - dice_coef(y_true, y_pred)\n","\n","def combined_loss(y_true, y_pred):\n","    ce = tf.keras.losses.SparseCategoricalCrossentropy()(y_true, y_pred)\n","    return ce + dice_loss(y_true, y_pred)\n","\n","class MeanIoUArgMax(tf.keras.metrics.MeanIoU):\n","    def __init__(self, num_classes=NUM_CLASSES, name=\"mean_iou\", dtype=None):\n","        super().__init__(num_classes=num_classes, name=name, dtype=dtype)\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        y_true = tf.squeeze(y_true, axis=-1)\n","        y_pred = tf.argmax(y_pred, axis=-1)\n","        return super().update_state(y_true, y_pred, sample_weight)\n","\n","for name, fn in sm.losses.__dict__.items():\n","    get_custom_objects()[name] = fn\n","for name, fn in sm.metrics.__dict__.items():\n","    get_custom_objects()[name] = fn\n","get_custom_objects().update({\n","    'dice_coef': dice_coef,\n","    'combined_loss': combined_loss,\n","    'MeanIoUArgMax': MeanIoUArgMax\n","})\n","\n"]},{"cell_type":"code","source":["!pip install --quiet mlxtend xgboost tqdm opencv-python-headless"],"metadata":{"id":"Fq1Wfneir2A9","executionInfo":{"status":"ok","timestamp":1745647030312,"user_tz":-180,"elapsed":2471,"user":{"displayName":"Abdlrahman Kobaissy","userId":"02284448119242242699"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import cv2\n","from tqdm import tqdm\n","from tensorflow.keras.models import load_model\n","from sklearn.model_selection import KFold\n","from xgboost import XGBClassifier\n","\n","model1 = load_model(\n","    MODEL_1_UNet,\n","    compile=False\n",")\n","model2 = load_model(\n","    MODEL_2_LINKNET,\n","    compile=False\n",")\n","model3 = load_model(\n","    MODEL_3_AttentionUNet,\n","    compile=False\n",")\n","model4 = load_model(\n","    MODEL_4_DGNet,\n","    compile=False\n",")\n","model5 = load_model(\n","    MODEL_5_Upp,\n","    compile=False\n",")\n","model1 = tf.keras.models.load_model(MODEL_1_UNet, compile=False)\n","model2 = tf.keras.models.load_model(MODEL_2_LINKNET, compile=False)\n","model3 = tf.keras.models.load_model(MODEL_3_AttentionUNet, compile=False)\n","model4 = tf.keras.models.load_model(MODEL_4_DGNet, compile=False)\n","model5 = tf.keras.models.load_model(MODEL_5_Upp, compile=False)"],"metadata":{"id":"VI2JvabUr4DR","executionInfo":{"status":"ok","timestamp":1745647084343,"user_tz":-180,"elapsed":54029,"user":{"displayName":"Abdlrahman Kobaissy","userId":"02284448119242242699"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["!pip install opencv-python-headless\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKwbw4V06pQK","executionInfo":{"status":"ok","timestamp":1745647086595,"user_tz":-180,"elapsed":2247,"user":{"displayName":"Abdlrahman Kobaissy","userId":"02284448119242242699"}},"outputId":"39693eac-5c58-4f30-856f-8289159a7ce0"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (2.0.2)\n"]}]},{"cell_type":"code","source":["for idx, m in enumerate([model1, model2, model3,model4,model5], 1):\n","    print(f\"Model{idx}.input_shape â†’\", m.input_shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-4IyEkv6EYJw","executionInfo":{"status":"ok","timestamp":1745647086623,"user_tz":-180,"elapsed":25,"user":{"displayName":"Abdlrahman Kobaissy","userId":"02284448119242242699"}},"outputId":"24da2850-8c90-492c-a882-f45e5c9e8f47"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Model1.input_shape â†’ (None, 224, 224, 3)\n","Model2.input_shape â†’ (None, 512, 512, 3)\n","Model3.input_shape â†’ (None, None, None, 3)\n","Model4.input_shape â†’ (None, 224, 224, 3)\n","Model5.input_shape â†’ (None, None, None, 3)\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"WwnLERol6omL"}},{"cell_type":"code","source":["!pip install gradio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lLch7bKv8CaS","executionInfo":{"status":"ok","timestamp":1745647095361,"user_tz":-180,"elapsed":8737,"user":{"displayName":"Abdlrahman Kobaissy","userId":"02284448119242242699"}},"outputId":"26e50bd8-dfa2-49ef-cb2e-9621f6ab4b06"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gradio\n","  Downloading gradio-5.27.0-py3-none-any.whl.metadata (16 kB)\n","Collecting aiofiles<25.0,>=22.0 (from gradio)\n","  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n","Collecting fastapi<1.0,>=0.115.2 (from gradio)\n","  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n","Collecting ffmpy (from gradio)\n","  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n","Collecting gradio-client==1.9.0 (from gradio)\n","  Downloading gradio_client-1.9.0-py3-none-any.whl.metadata (7.1 kB)\n","Collecting groovy~=0.1 (from gradio)\n","  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n","Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n","Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart>=0.0.18 (from gradio)\n","  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n","Collecting ruff>=0.9.3 (from gradio)\n","  Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n","  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting starlette<1.0,>=0.40.0 (from gradio)\n","  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n","Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n","  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (2025.3.2)\n","Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (15.0.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.8)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Downloading gradio-5.27.0-py3-none-any.whl (54.0 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.9.0-py3-none-any.whl (322 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.6/322.6 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n","Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n","Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n","Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m120.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n","Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n","Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n","Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.27.0 gradio-client-1.9.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.7 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import gradio as gr\n","import matplotlib.pyplot as plt\n","\n","# your five TF/Keras models\n","base_models = [model1, model2, model3, model4, model5]\n","\n","# fallback for any dynamicâ€shape models\n","_manual_map = {\n","    model1: (224, 224),\n","    model2: (512, 512),\n","    model3: (512, 512),\n","    model4: (224, 224),\n","    model5: (512, 512),\n","}\n","\n","def get_native_size(m):\n","    h, w = m.input_shape[1], m.input_shape[2]\n","    if h is None or w is None or h == 0 or w == 0:\n","        return _manual_map[m]\n","    return (h, w)\n","\n","def soft_voting_mask(img):\n","    H, W = img.shape[:2]\n","    C = base_models[0].output_shape[-1]\n","    acc = np.zeros((H, W, C), dtype=np.float32)\n","    for m in base_models:\n","        h_n, w_n = get_native_size(m)\n","        inp = cv2.resize(img, (w_n, h_n), interpolation=cv2.INTER_AREA)\n","        pm  = m.predict(inp[None], verbose=0)[0]\n","        for c in range(C):\n","            acc[..., c] += cv2.resize(pm[..., c], (W, H), interpolation=cv2.INTER_LINEAR)\n","    acc /= len(base_models)\n","    mask = np.argmax(acc, axis=-1).astype(np.uint8)\n","    conf = np.max(acc, axis=-1)\n","    return mask, conf\n","\n","def ensemble_predict(image):\n","    img = np.array(image)\n","    img_f = img.astype(np.float32)/255.0\n","    mask, conf = soft_voting_mask(img_f)\n","\n","    # red overlay\n","    overlay = img.copy()\n","    overlay[mask>0] = [255,0,0]\n","    mask_overlay = cv2.addWeighted(overlay, 0.5, img, 0.5, 0)\n","\n","    # confidence heatmap\n","    conf_img = (conf*255).astype(np.uint8)\n","    conf_bgr = cv2.applyColorMap(conf_img, cv2.COLORMAP_HOT)\n","    conf_vis = conf_bgr[..., ::-1]\n","\n","    # class percentages\n","    total = mask.size\n","    lines = [f\"Class {cls}: {100*np.sum(mask==cls)/total:4.1f}%\"\n","             for cls in range(mask.max()+1)]\n","    pct = \"\\n\".join(lines)\n","\n","    return mask_overlay, conf_vis, pct\n","\n","css = \"\"\"\n",".gradio-container {\n","  max-width: 900px !important;\n","  margin: auto;\n","  padding: 2rem;\n","  background: #ffffff;\n","  border-radius: 12px;\n","  box-shadow: 0 4px 12px rgba(0,0,0,0.1);\n","}\n","#mask-out, #conf-out {\n","  border-radius: 8px;\n","  box-shadow: 0 2px 6px rgba(0,0,0,0.1);\n","}\n",".gr-button {\n","  background-color: #e63946;\n","  color: white;\n","  border: none;\n","  padding: 0.75rem 1.5rem;\n","  border-radius: 6px;\n","  font-size: 1rem;\n","}\n",".gr-button:hover {\n","  background-color: #d62828;\n","}\n",".gr-box {\n","  background: #f8f9fa;\n","  border-radius: 8px;\n","  padding: 1rem;\n","  box-shadow: inset 0 1px 3px rgba(0,0,0,0.05);\n","}\n","\"\"\"\n","\n","with gr.Blocks(css=css, theme=gr.themes.Base()) as demo:\n","    gr.Markdown(\"<h1 style='text-align:center;color:#333;'>ðŸ§  Soft-Voting Ensemble Demo</h1>\")\n","    gr.Markdown(\"<p style='text-align:center;color:#555;'>Upload an image to get a red mask overlay, confidence heatmap, & class breakdown.</p>\")\n","\n","    with gr.Row():\n","        inp = gr.Image(type=\"pil\", label=\"Input Image\", elem_id=\"input-img\")\n","    with gr.Row():\n","        with gr.Column():\n","            gr.Markdown(\"**Mask Overlay**\", elem_id=\"mask-title\")\n","            m_out = gr.Image(type=\"numpy\", label=None, elem_id=\"mask-out\")\n","        with gr.Column():\n","            gr.Markdown(\"**Confidence Heatmap**\", elem_id=\"conf-title\")\n","            c_out = gr.Image(type=\"numpy\", label=None, elem_id=\"conf-out\")\n","    pct = gr.Textbox(label=\"Class Distribution\", interactive=False, elem_id=\"dist-box\")\n","\n","    inp.change(fn=ensemble_predict,\n","               inputs=inp,\n","               outputs=[m_out, c_out, pct],\n","               show_progress=True)\n","\n","demo.launch()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":650},"id":"2n8nFF4c7jQT","executionInfo":{"status":"ok","timestamp":1745647100430,"user_tz":-180,"elapsed":5055,"user":{"displayName":"Abdlrahman Kobaissy","userId":"02284448119242242699"}},"outputId":"2266f16a-03f9-4713-93a6-e81070519ddf"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://431c0e81bc80ef05df.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://431c0e81bc80ef05df.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":17}]}],"metadata":{"colab":{"provenance":[{"file_id":"1_k7ogP1xm8XVyrbeskFh20BnYuW2Ycb1","timestamp":1745634566400},{"file_id":"1-VF2VDPbxXDOogmxXajKBr5yhLNQsvtw","timestamp":1745617811043},{"file_id":"1g5ACu-cLTqhufcsgYQON4NX26YE8X6zm","timestamp":1745466123311}],"gpuType":"L4","machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}