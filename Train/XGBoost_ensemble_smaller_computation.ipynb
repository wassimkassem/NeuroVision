{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Engineer-Ayesha-Shafique/Brain-Tumor-Segmentation-and-Detection-using-UNET-and-Watershed-in-Python/blob/main/Brain_Tumor_Segmentation_and_Detection_using_UNET_and_Watershed_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0LHr_cN94aF",
        "outputId": "cc02c951-6584-4052-d4a3-622d4029a052"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive' ,force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yacw50PTTLCQ"
      },
      "source": [
        "#MOE\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8aJ2oKaYnd1M"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "BASE_MODEL_PATH = \"/content/drive/MyDrive/Project_41725\"\n",
        "MODEL_1 = os.path.join(BASE_MODEL_PATH, \"files\" , \"UNetModified\" , \"model.h5\")\n",
        "MODEL_2 = os.path.join(BASE_MODEL_PATH, \"files\" , \"LinkNet\" , \"model.h5\")\n",
        "MODEL_3 = os.path.join(BASE_MODEL_PATH, \"files\", \"aug_pass\" , \"model_512.h5\")\n",
        "MODEL_4 = os.path.join(BASE_MODEL_PATH, \"files\", \"DG\" , \"model.h5\")\n",
        "MODEL_5 = os.path.join(BASE_MODEL_PATH, \"files\", \"DG\" , \"model_256.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNQiO38M8v-4",
        "outputId": "d864ddb9-dcd3-411a-a93d-7d9b1fb829de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ No GPU detected for TensorFlow\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    print(f\"✅ TensorFlow will use {len(gpus)} GPU(s)\")\n",
        "else:\n",
        "    print(\"⚠️ No GPU detected for TensorFlow\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1ixsseaB8uIZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from xgboost import XGBClassifier\n",
        "from tqdm import tqdm\n",
        "import imageio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jwPlOqg0q_bu"
      },
      "outputs": [],
      "source": [
        "# ── 1) Imports & constants ─────────────────────────────────────────────────────\n",
        "\n",
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, Activation, Lambda\n",
        ")\n",
        "\n",
        "INPUT_SHAPE = (224, 224, 3)\n",
        "NUM_CLASSES = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VHzsjqsR5HMl"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet segmentation-models tensorflow-addons\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rQpQpgEf1BWw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1052673b-ff30-438b-f3fa-75c40bf1caa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation Models: using `tf.keras` framework.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "\n",
        "import segmentation_models as sm\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D, BatchNormalization, Activation,\n",
        "    MaxPool2D\n",
        ")\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "\n",
        "sm.set_framework('tf.keras')\n",
        "\n",
        "BASE_MODEL_PATH = \"/content/drive/MyDrive/Project_41725\"\n",
        "MODEL_1_UNet = os.path.join(BASE_MODEL_PATH, \"files\" , \"UNetModified\" , \"model.h5\")\n",
        "MODEL_2_LINKNET = os.path.join(BASE_MODEL_PATH, \"files\" ,\"LinkNet\", \"modell.h5\")\n",
        "MODEL_3_AttentionUNet = os.path.join(BASE_MODEL_PATH, \"files\", \"aug_pass\", \"model_512.h5\")\n",
        "MODEL_4_DGNet = MODEL_4\n",
        "MODEL_5_Upp =  MODEL_5\n",
        "INPUT_SHAPE = (512, 512, 3)\n",
        "ds_path = \"/content/drive/MyDrive/Project_41725/newdata/train_maskimg\"\n",
        "mask_dir = \"/content/drive/MyDrive/Project_41725/newdata/train_maskimg/masks\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sTVIxx_sD755",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f984af5-3d83-4200-b0f6-161496a2c3b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 1216, Val: 348, Test: 174\n"
          ]
        }
      ],
      "source": [
        "# In a notebook cell, before any cv2 imports:\n",
        "!pip install --quiet opencv-python-headless\n",
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "# 1) Import TF first and set memory growth (fallback to experimental)\n",
        "import tensorflow as tf\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        try:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        except Exception as e:\n",
        "            print(f\"[GPU] Could not set memory growth: {e}\")\n",
        "    print(f\"[GPU] Detected {len(gpus)} GPU(s).\")\n",
        "\n",
        "# 2) Now import the rest\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import (\n",
        "    ModelCheckpoint, CSVLogger, ReduceLROnPlateau,\n",
        "    EarlyStopping, TensorBoard\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from xgboost import XGBClassifier\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "\"\"\" Global parameters \"\"\"\n",
        "Height = 512\n",
        "Width  = 512\n",
        "\n",
        "def create_folder(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def load_dataset(path_dataset, val_ratio=0.2, test_ratio=0.1, random_state=42):\n",
        "    img_dir  = os.path.join(path_dataset, \"images\")\n",
        "    mask_dir = os.path.join(path_dataset, \"masks\")\n",
        "\n",
        "    image_exts = ('.png', '.jpg', '.jpeg')\n",
        "    images = sorted([\n",
        "        os.path.join(img_dir, f)\n",
        "        for f in os.listdir(img_dir)\n",
        "        if f.lower().endswith(image_exts)\n",
        "    ])\n",
        "\n",
        "\n",
        "    mask_exts = ('.tif', '.tiff')\n",
        "    masks = sorted([\n",
        "        os.path.join(mask_dir, f)\n",
        "        for f in os.listdir(mask_dir)\n",
        "        if f.lower().endswith(mask_exts)\n",
        "    ])\n",
        "\n",
        "    if not images:\n",
        "        raise RuntimeError(f\"No images found in {img_dir}\")\n",
        "    if not masks:\n",
        "        raise RuntimeError(f\"No masks found in {mask_dir}\")\n",
        "\n",
        "    images_lookup = {\n",
        "        os.path.splitext(os.path.basename(p))[0]: p\n",
        "        for p in images\n",
        "    }\n",
        "#MildDemented_0a7b1321-eba0-40dc-85b8-de34241554a2_jpg.rf.70370fcd9ac0fb82f91d27f558053d84.tif\n",
        "    pairs = []\n",
        "    for m in masks:\n",
        "        base = os.path.splitext(os.path.basename(m))[0]\n",
        "        if base.endswith('_mask'):\n",
        "            root = base[:-5]\n",
        "            img_path = images_lookup.get(root)\n",
        "            if img_path:\n",
        "                pairs.append((img_path, m))\n",
        "\n",
        "    if not pairs:\n",
        "        raise RuntimeError(\"No matching image↔mask pairs found!\")\n",
        "\n",
        "    trainval, test = train_test_split(pairs, test_size=test_ratio, random_state=random_state)\n",
        "    val_frac = val_ratio / (1.0 - test_ratio)\n",
        "    train, val = train_test_split(trainval, test_size=val_frac, random_state=random_state)\n",
        "\n",
        "    train_imgs, train_masks = zip(*train)\n",
        "    val_imgs,   val_masks   = zip(*val)\n",
        "    test_imgs,  test_masks  = zip(*test)\n",
        "\n",
        "    return (\n",
        "        list(train_imgs), list(train_masks),\n",
        "        list(val_imgs),   list(val_masks),\n",
        "        list(test_imgs),  list(test_masks)\n",
        "    )\n",
        "\n",
        "def read_image_file(path_img):\n",
        "    path = path_img.decode('utf-8') if isinstance(path_img, bytes) else path_img\n",
        "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    img = cv2.resize(img, (Width, Height)) / 255.0\n",
        "    return img.astype(np.float32)\n",
        "\n",
        "def read_mask_file(path_mask):\n",
        "    path = path_mask.decode('utf-8') if isinstance(path_mask, bytes) else path_mask\n",
        "    mask = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "    if mask.ndim == 3:\n",
        "        mask = mask[..., 0]\n",
        "    mask = cv2.resize(mask, (Width, Height), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    # ✅ Clip to [0, 4], not [0, 3]:\n",
        "    mask = np.clip(mask, 0, NUM_CLASSES-1)\n",
        "\n",
        "    # Convert to integer class IDs\n",
        "    mask = mask.astype(np.int32)\n",
        "\n",
        "    # Add the channel dim back\n",
        "    return mask[..., None]\n",
        "\n",
        "def tf_parse(path_img, path_mask):\n",
        "    # Tell numpy_function: img→float32, mask→int32\n",
        "    img, mask = tf.numpy_function(\n",
        "        lambda pi, pm: (read_image_file(pi), read_mask_file(pm)),\n",
        "        [path_img, path_mask],\n",
        "        [tf.float32, tf.int32]          # <-- second output is now int32\n",
        "    )\n",
        "    img.set_shape([Height, Width, 3])\n",
        "    mask.set_shape([Height, Width, 1])\n",
        "    return img, mask\n",
        "\n",
        "def tf_dataset(inputs, targets, batch_size=2):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((inputs, targets))\n",
        "    ds = ds.map(tf_parse, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "def edit_mask_images(mask_dir, func, output_dir=None):\n",
        "    out_dir = output_dir or mask_dir\n",
        "    create_folder(out_dir)\n",
        "    exts = ('.tif')\n",
        "    for fname in os.listdir(mask_dir):\n",
        "        if not fname.lower().endswith(exts):\n",
        "            continue\n",
        "        in_path  = os.path.join(mask_dir, fname)\n",
        "        mask     = cv2.imread(in_path, cv2.IMREAD_UNCHANGED)\n",
        "        edited   = func(mask)\n",
        "        cv2.imwrite(os.path.join(out_dir, fname), edited)\n",
        "    print(f\"[edit_mask_images] Applied edits to masks in {out_dir}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    create_folder(\"/content/drive/MyDrive/Project_41725/files\")\n",
        "\n",
        "    batch_size = 16\n",
        "    lr         = 1e-4\n",
        "    epochs_num     = 100\n",
        "    path_model = os.path.join(\"/content/drive/MyDrive/Project_41725/files\", \"model.h5\")\n",
        "    path_csv   = os.path.join(\"/content/drive/MyDrive/Project_41725/files\", \"log.csv\")\n",
        "\n",
        "    ds_path = \"/content/drive/MyDrive/Project_41725/newdata/train_maskimg\"\n",
        "    train_imgs, train_masks, val_imgs, val_masks, test_imgs, test_masks = load_dataset(ds_path)\n",
        "\n",
        "    print(f\"Train: {len(train_imgs)}, Val: {len(val_imgs)}, Test: {len(test_imgs)}\")\n",
        "\n",
        "    train_ds = tf_dataset(train_imgs, train_masks, batch_size=batch_size)\n",
        "    val_ds   = tf_dataset(val_imgs,   val_masks,   batch_size=batch_size)\n",
        "    test_ds  = tf_dataset(test_imgs,  test_masks,  batch_size=batch_size)\n",
        "\n",
        "    # Build, compile and fit your model below:\n",
        "    # model = Unet_model((Height, Width, 3))\n",
        "    # model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coeff])\n",
        "    # callbacks = [ModelCheckpoint(...), ...]\n",
        "    # model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=callbacks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "REl8w4qgr0Ur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea84f65-f356-4030-be53-d8510e78767b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manifest CSVs written.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# assuming you’ve re-run the load_dataset cell in XGBoost_ensemble.ipynb\n",
        "# so train_imgs, train_masks, test_imgs are available:\n",
        "\n",
        "pd.DataFrame({'image_path': train_imgs}).to_csv('train_images.csv', index=False)\n",
        "pd.DataFrame({'mask_path':  train_masks}).to_csv('train_masks.csv',  index=False)\n",
        "pd.DataFrame({'image_path': test_imgs }).to_csv('test_images.csv',  index=False)\n",
        "print(\"Manifest CSVs written.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NMrqwAWO8VHo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import (\n",
        "    ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
        ")\n",
        "import os\n",
        "# Make sure segmentation_models picks up tf.keras, not plain keras\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "import segmentation_models as sm\n",
        "\n",
        "# Hyper‑params & paths\n",
        "NUM_CLASSES = 5\n",
        "INPUT_SHAPE = (512, 512, 3)\n",
        "EPOCHS      = 160\n",
        "path_model  = \"/content/drive/MyDrive/Project_41725/XGBoost/files/model.h5\"\n",
        "path_csv    = \"/content/drive/MyDrive/Project_41725/XGBoost/files/log.csv\"\n",
        "\n",
        "# 0) kill any existing graph/state\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 3) Define losses & metrics\n",
        "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
        "    y_true = tf.squeeze(y_true, axis=-1)\n",
        "    y_true_o = tf.one_hot(tf.cast(y_true, tf.int32), depth=NUM_CLASSES)\n",
        "    y_true_f = tf.reshape(y_true_o, [-1, NUM_CLASSES])\n",
        "    y_pred_f = tf.reshape(y_pred,   [-1, NUM_CLASSES])\n",
        "    inter = tf.reduce_sum(y_true_f * y_pred_f, axis=0)\n",
        "    denom = tf.reduce_sum(y_true_f, axis=0) + tf.reduce_sum(y_pred_f, axis=0)\n",
        "    dice_per_class = (2. * inter + smooth) / (denom + smooth)\n",
        "    return tf.reduce_mean(dice_per_class)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)\n",
        "\n",
        "def combined_loss(y_true, y_pred):\n",
        "    ce = tf.keras.losses.SparseCategoricalCrossentropy()(y_true, y_pred)\n",
        "    return ce + dice_loss(y_true, y_pred)\n",
        "\n",
        "class MeanIoUArgMax(tf.keras.metrics.MeanIoU):\n",
        "    def __init__(self, num_classes=NUM_CLASSES, name=\"mean_iou\", dtype=None):\n",
        "        super().__init__(num_classes=num_classes, name=name, dtype=dtype)\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_true = tf.squeeze(y_true, axis=-1)\n",
        "        y_pred = tf.argmax(y_pred, axis=-1)\n",
        "        return super().update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "for name, fn in sm.losses.__dict__.items():\n",
        "    get_custom_objects()[name] = fn\n",
        "for name, fn in sm.metrics.__dict__.items():\n",
        "    get_custom_objects()[name] = fn\n",
        "get_custom_objects().update({\n",
        "    'dice_coef': dice_coef,\n",
        "    'combined_loss': combined_loss,\n",
        "    'MeanIoUArgMax': MeanIoUArgMax\n",
        "})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Fq1Wfneir2A9"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet mlxtend xgboost tqdm opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VI2JvabUr4DR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.model_selection import KFold\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "model1 = load_model(\n",
        "    MODEL_1_UNet,\n",
        "    compile=False\n",
        ")\n",
        "model2 = load_model(\n",
        "    MODEL_2_LINKNET,\n",
        "    compile=False\n",
        ")\n",
        "model3 = load_model(\n",
        "    MODEL_3_AttentionUNet,\n",
        "    compile=False\n",
        ")\n",
        "model4 = load_model(\n",
        "    MODEL_4_DGNet,\n",
        "    compile=False\n",
        ")\n",
        "model5 = load_model(\n",
        "    MODEL_5_Upp,\n",
        "    compile=False\n",
        ")\n",
        "model1 = tf.keras.models.load_model(MODEL_1_UNet, compile=False)\n",
        "model2 = tf.keras.models.load_model(MODEL_2_LINKNET, compile=False)\n",
        "model3 = tf.keras.models.load_model(MODEL_3_AttentionUNet, compile=False)\n",
        "model4 = tf.keras.models.load_model(MODEL_4_DGNet, compile=False)\n",
        "model5 = tf.keras.models.load_model(MODEL_5_Upp, compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679,
          "referenced_widgets": [
            "ea82f162305b4793a7737438ab034dd3",
            "02b49f1853ae4fc5a002efdf857880d2",
            "26b8a444923841db94dd5ff0ba98af7a",
            "0dfcb531c25249538b40825b885fcba6",
            "4f31a6cee417452683c0d3460fc14c90",
            "484314ce9f5b40f7be3553b2cb8e3815",
            "eaf0423fbf95484f8fd667d5de6c7074",
            "a08480b8bd1641aba2db6cc0d7199b9c",
            "a9c83b29ba794b10b287fce2c792a58b",
            "b01de9444583459cae93cf6ba1e599c0",
            "48fa5a4d2e3247779371a16e4f65888d",
            "53411b6efebc4352b4472b6c9008d2d7",
            "eeadaaab17774c18a31ada8bc08e1bcb",
            "03e095832471456ebab0c5cde3e9dc20",
            "6abf5be6d8c84331a0c390cc4c529e50",
            "46bb0266594b449ca9dbb64c88ef09cb",
            "d5f25eb2206140178120b4d5ce7ac53c",
            "18421ab1de0949eb94e40874cf8bcb90",
            "ae6d7d9bfc5f485893a76e9325eb4d4c",
            "4d6717f1d4d0458398904d280bc2eb05",
            "49aaebcaacb84e04aef4c74346ef69cb",
            "1539011ac6d749c8a1a33938afa590a6"
          ]
        },
        "id": "282r_dnHNmj7",
        "outputId": "3199fc69-a51c-4248-a082-19f7cdaca4ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 Loading base segmentation models…\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea82f162305b4793a7737438ab034dd3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Base models:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 Sampling pixels & building training set…\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53411b6efebc4352b4472b6c9008d2d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Images:   0%|          | 0/300 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  → initial X_train: (60000, 25), y_train: (60000,)\n",
            "🔄 Training RandomForest…\n",
            "🔄 Training XGBoost…\n",
            "⏳ Fitting RF…\n",
            "⏳ Fitting XGB…\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:42:54] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 Building soft-voting ensemble…\n",
            "💾 Saving trained models…\n",
            "✅ Models written to /content/drive/MyDrive/Project_41725/models_new\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:43:02] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "segment_image: no such file → /content/drive/MyDrive/Project_41725/newdata/test/image123.png",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-ab4542d2287a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mtest_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Project_41725/newdata/test/image123.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ensemble_seg.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-ab4542d2287a>\u001b[0m in \u001b[0;36msegment_image\u001b[0;34m(img_path, out_path)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;31m# 0) sanity check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"segment_image: no such file → {img_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;31m# 1) read & normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mimg_bgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: segment_image: no such file → /content/drive/MyDrive/Project_41725/newdata/test/image123.png"
          ]
        }
      ],
      "source": [
        "'''\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from tqdm.auto import tqdm\n",
        "import joblib\n",
        "\n",
        "# ─── CONFIG ────────────────────────────────────────────────────────────────\n",
        "BASE_MODEL_DIR     = \"/content/drive/MyDrive/Project_41725/files\"\n",
        "MODEL_DIR          = \"/content/drive/MyDrive/Project_41725/models_new\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "MODEL_PATHS        = [\n",
        "    \"UNetModified/model.h5\",\n",
        "    \"LinkNet/model.h5\",\n",
        "    \"aug_pass/model_512.h5\",\n",
        "    \"DG/model.h5\",\n",
        "    \"DG/model_256.h5\",\n",
        "]\n",
        "IMG_DIR            = \"/content/drive/MyDrive/Project_41725/newdata/train_maskimg/images\"\n",
        "MSK_DIR            = \"/content/drive/MyDrive/Project_41725/newdata/train_maskimg/masks\"\n",
        "IMG_EXTS           = (\".png\", \".jpg\", \".jpeg\")\n",
        "MSK_EXTS           = (\".tif\", \".tiff\")\n",
        "SAMPLES_PER_IMAGE  = 200\n",
        "MAX_IMAGES         = 300\n",
        "\n",
        "# ─── LOAD BASE MODELS ─────────────────────────────────────────────────────\n",
        "print(\"🔄 Loading base segmentation models…\")\n",
        "base_models = [\n",
        "    load_model(os.path.join(BASE_MODEL_DIR, p), compile=False)\n",
        "    for p in tqdm(MODEL_PATHS, desc=\"Base models\")\n",
        "]\n",
        "NUM_CLASSES = base_models[0].output_shape[-1]\n",
        "IN_H, IN_W  = base_models[0].input_shape[1:3]\n",
        "\n",
        "# ─── PAIR UP IMAGES ↔ MASKS FOR LATER INJECTION ────────────────────────────\n",
        "# assume mask file is named \"<stem>_mask.tif\" matching \"<stem>.png\"\n",
        "images_lookup = {\n",
        "    os.path.splitext(os.path.basename(p))[0]: p\n",
        "    for ext in IMG_EXTS\n",
        "    for p in glob(os.path.join(IMG_DIR, f\"*{ext}\"))\n",
        "}\n",
        "pairs = []\n",
        "for ext in MSK_EXTS:\n",
        "    for msk_path in glob(os.path.join(MSK_DIR, f\"*{ext}\")):\n",
        "        stem = os.path.splitext(os.path.basename(msk_path))[0]\n",
        "        if stem.endswith(\"_mask\"):\n",
        "            key = stem[:-5]\n",
        "            img_p = images_lookup.get(key)\n",
        "            if img_p:\n",
        "                pairs.append((img_p, msk_path))\n",
        "\n",
        "# ─── FEATURE EXTRACTION ───────────────────────────────────────────────────\n",
        "def get_pixel_probs(img, models):\n",
        "    feats = []\n",
        "    for m in models:\n",
        "        pm = m.predict(img[None], verbose=0)[0]               # (H,W,C)\n",
        "        feats.append(pm.reshape(-1, NUM_CLASSES))            # (H*W,C)\n",
        "    return np.concatenate(feats, axis=1)                     # (H*W, M*C)\n",
        "\n",
        "# ─── SAMPLE TRAINING DATA ─────────────────────────────────────────────────\n",
        "print(\"🔄 Sampling pixels & building training set…\")\n",
        "train_imgs  = sorted(pairs, key=lambda x: x[0])[:MAX_IMAGES]\n",
        "X_chunks, y_chunks = [], []\n",
        "for img_p, msk_p in tqdm(train_imgs, desc=\"Images\"):\n",
        "    img = cv2.imread(img_p)[..., ::-1] / 255.0\n",
        "    msk = cv2.imread(msk_p, cv2.IMREAD_GRAYSCALE)\n",
        "    img_rs = cv2.resize(img, (IN_W, IN_H), cv2.INTER_AREA)\n",
        "    msk_rs = cv2.resize(msk, (IN_W, IN_H), cv2.INTER_NEAREST).ravel()\n",
        "    P = get_pixel_probs(img_rs, base_models)               # (H*W, M*C)\n",
        "    idxs = np.random.choice(IN_H*IN_W, SAMPLES_PER_IMAGE, replace=False)\n",
        "    X_chunks.append(P[idxs]);  y_chunks.append(msk_rs[idxs])\n",
        "\n",
        "X_train = np.vstack(X_chunks)\n",
        "y_train = np.concatenate(y_chunks)\n",
        "print(f\"  → initial X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "\n",
        "# ─── INJECT MISSING CLASSES ────────────────────────────────────────────────\n",
        "present = set(np.unique(y_train))\n",
        "missing = set(range(NUM_CLASSES)) - present\n",
        "if missing:\n",
        "    print(f\"⚠️ Missing classes: {missing}, injecting one pixel each…\")\n",
        "    for cls in missing:\n",
        "        for img_p, msk_p in pairs:\n",
        "            m_full = cv2.imread(msk_p, cv2.IMREAD_GRAYSCALE)\n",
        "            ys, xs = np.where(m_full == cls)\n",
        "            if len(ys):\n",
        "                # take first occurrence\n",
        "                y0, x0 = ys[0], xs[0]\n",
        "                img_full = cv2.imread(img_p)[..., ::-1] / 255.0\n",
        "                img_rs   = cv2.resize(img_full, (IN_W, IN_H), cv2.INTER_AREA)\n",
        "                P        = get_pixel_probs(img_rs, base_models)\n",
        "                # map full-coord → resized-coord\n",
        "                yr = int(y0 * IN_H / m_full.shape[0])\n",
        "                xr = int(x0 * IN_W / m_full.shape[1])\n",
        "                feat     = P[yr*IN_W + xr]\n",
        "                X_train  = np.vstack([X_train, feat])\n",
        "                y_train  = np.hstack([y_train, cls])\n",
        "                break\n",
        "    print(f\"  → now y_train covers classes: {np.unique(y_train)}\")\n",
        "\n",
        "# ─── TRAIN META-LEARNERS ───────────────────────────────────────────────────\n",
        "print(\"🔄 Training RandomForest…\")\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "print(\"🔄 Training XGBoost…\")\n",
        "xgb = XGBClassifier(\n",
        "    objective=\"multi:softprob\",\n",
        "    use_label_encoder=False,\n",
        "    eval_metric=\"mlogloss\",\n",
        "    n_estimators=100,\n",
        "    max_depth=3,\n",
        "    tree_method=\"hist\",\n",
        "    random_state=42\n",
        ")\n",
        "print(\"⏳ Fitting RF…\");  rf.fit(X_train, y_train)\n",
        "print(\"⏳ Fitting XGB…\"); xgb.fit(X_train, y_train)\n",
        "\n",
        "# ─── BUILD SOFT-VOTING ENSEMBLE ───────────────────────────────────────────\n",
        "print(\"🔄 Building soft-voting ensemble…\")\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=[(\"rf\", rf), (\"xgb\", xgb)],\n",
        "    voting=\"soft\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "ensemble.fit(X_train, y_train)\n",
        "\n",
        "# ─── SAVE ALL MODELS ───────────────────────────────────────────────────────\n",
        "print(\"💾 Saving trained models…\")\n",
        "joblib.dump(rf,                     os.path.join(MODEL_DIR, \"rf_meta.pkl\"))\n",
        "xgb.save_model(                     os.path.join(MODEL_DIR, \"xgb_meta.model\"))\n",
        "joblib.dump(ensemble,               os.path.join(MODEL_DIR, \"ensemble_soft_voting.pkl\"))\n",
        "print(\"✅ Models written to\", MODEL_DIR)\n",
        "\n",
        "# ─── UPDATED segment_image WITH PATH CHECK ─────────────────────────────────\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def segment_image(img_path, out_path=\"seg.png\"):\n",
        "    # 0) sanity check\n",
        "    if not os.path.isfile(img_path):\n",
        "        raise FileNotFoundError(f\"segment_image: no such file → {img_path}\")\n",
        "    # 1) read & normalize\n",
        "    img_bgr = cv2.imread(img_path)\n",
        "    if img_bgr is None:\n",
        "        raise ValueError(f\"segment_image: failed to decode image → {img_path}\")\n",
        "    img = img_bgr[..., ::-1] / 255.0\n",
        "    H, W = img.shape[:2]\n",
        "\n",
        "    # 2) resize to model input\n",
        "    img_rs = cv2.resize(img, (IN_W, IN_H), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # 3) feature extraction & ensemble predict\n",
        "    P   = get_pixel_probs(img_rs, base_models)    # (IN_H*IN_W, M·C)\n",
        "    lbl = ensemble.predict(P)                      # (IN_H*IN_W,)\n",
        "    mask = lbl.reshape(IN_H, IN_W).astype(np.uint8)\n",
        "\n",
        "    # 4) upsample & save\n",
        "    mask_full = cv2.resize(mask, (W, H), cv2.INTER_NEAREST)\n",
        "    cv2.imwrite(out_path, mask_full)\n",
        "    print(f\"🔍 Saved segmentation → {out_path}\")\n",
        "    return mask_full\n",
        "\n",
        "\n",
        "# ─── USAGE ─────────────────────────────────────────────────────────────────\n",
        "if __name__==\"__main__\":\n",
        "    test_img = \"/content/drive/MyDrive/Project_41725/newdata/train_maskimg/\"\n",
        "    _ = segment_image(test_img, out_path=os.path.join(MODEL_DIR,\"ensemble_seg.png\"))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "E809l73-WREc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "2151d2b1-ee7c-4432-f7c6-7c263f730f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading base segmentation models…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Base models:  20%|██        | 1/5 [00:09<00:39,  9.94s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0af1f5928a1d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Base model not found: {path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mbase_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# derive some handy constants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msaving_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_legacy_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             model = saving_utils.model_from_config(\n\u001b[0m\u001b[1;32m    134\u001b[0m                 \u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_replace_nested_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     return serialization.deserialize_keras_object(\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODULE_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/serialization.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"custom_objects\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                 deserialized_obj = cls.from_config(\n\u001b[0m\u001b[1;32m    496\u001b[0m                     \u001b[0mcls_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                     custom_objects={\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/model.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional_from_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             return functional_from_config(\n\u001b[0m\u001b[1;32m    583\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mfunctional_from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    568\u001b[0m                     \u001b[0mnode_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_data_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                         \u001b[0mprocess_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                     \u001b[0;31m# If the node does not have all inbound layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mprocess_node\u001b[0;34m(layer, node_data)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# Call layer on its inputs, thus creating the node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;31m# and building the layer if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;31m# 4. Call build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0;31m##########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, call_spec)\u001b[0m\n\u001b[1;32m   1369\u001b[0m                 \u001b[0mclass_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m             )\n\u001b[0;32m-> 1371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mshapes_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m             \u001b[0;31m# Check input spec again (after build, since self.input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0;31m# may have been updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36mbuild_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                 \u001b[0moriginal_build_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0;31m# Record build config.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_build_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_depthwise_conv.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth_multiplier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         )\n\u001b[0;32m--> 172\u001b[0;31m         self.kernel = self.add_weight(\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"kernel\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepthwise_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, shape, initializer, dtype, trainable, autocast, regularizer, constraint, aggregation, name)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m             variable = backend.Variable(\n\u001b[0m\u001b[1;32m    545\u001b[0m                 \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initializer, shape, dtype, trainable, autocast, aggregation, name)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_with_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/core.py\u001b[0m in \u001b[0;36m_initialize_with_initializer\u001b[0;34m(self, initializer)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_initialize_with_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_deferred_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/core.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         self._value = tf.Variable(\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_variable_call\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m       \u001b[0mvariable_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvariable_call\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvariable_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_call\u001b[0;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape, experimental_enable_variable_lifting, **kwargs)\u001b[0m\n\u001b[1;32m   1228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maggregation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m       \u001b[0maggregation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariableAggregation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m     return previous_getter(\n\u001b[0m\u001b[1;32m   1231\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kws)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36mdefault_variable_creator_v2\u001b[0;34m(next_creator, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource_variable_ops\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m   return resource_variable_ops.default_variable_creator_v2(\n\u001b[0m\u001b[1;32m     52\u001b[0m       next_creator=next_creator, **kwds)\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mdefault_variable_creator_v2\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m       \"experimental_enable_variable_lifting\", None)\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m   return ResourceVariable(\n\u001b[0m\u001b[1;32m    358\u001b[0m       \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m       \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvariable_call\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvariable_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape, handle, experimental_enable_variable_lifting)\u001b[0m\n\u001b[1;32m   1871\u001b[0m                              handle=handle)\n\u001b[1;32m   1872\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1873\u001b[0;31m       self._init_from_args(\n\u001b[0m\u001b[1;32m   1874\u001b[0m           \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape, validate_shape, experimental_enable_variable_lifting)\u001b[0m\n\u001b[1;32m   2060\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_uid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_position\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_uid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m               \u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapped_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2062\u001b[0;31m             initial_value = ops.convert_to_tensor(\n\u001b[0m\u001b[1;32m   2063\u001b[0m                 initial_value, name=\"initial_value\", dtype=dtype)\n\u001b[1;32m   2064\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minner_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "'''\n",
        "# ─── 0) INSTALL & IMPORTS ──────────────────────────────────────────────────\n",
        "!pip install --quiet opencv-python-headless xgboost tqdm\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.display import display\n",
        "import os, cv2, joblib, numpy as np, matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.base import BaseEstimator\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ─── 1) CONFIG ─────────────────────────────────────────────────────────────\n",
        "MODEL_DIR        = \"/content/drive/MyDrive/Project_41725/models_new\"\n",
        "BASE_MODEL_DIR   = \"/content/drive/MyDrive/Project_41725/files\"\n",
        "MODEL_PATHS      = [\n",
        "    \"UNetModified/model.h5\",\n",
        "    \"LinkNet/model.h5\",\n",
        "    \"aug_pass/model_512.h5\",\n",
        "    \"DG/model.h5\",\n",
        "    \"DG/model_256.h5\",\n",
        "]\n",
        "# how many pixels *per class* per image to sample\n",
        "SAMPLES_PER_CLASS_PER_IMAGE = 50\n",
        "\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# ─── 2) LOAD BASE SEGMENTATION MODELS ───────────────────────────────────────\n",
        "print(\"Loading base segmentation models…\")\n",
        "base_models = []\n",
        "for rel in tqdm(MODEL_PATHS, desc=\"Base models\"):\n",
        "    path = os.path.join(BASE_MODEL_DIR, rel)\n",
        "    if not os.path.isfile(path):\n",
        "        raise FileNotFoundError(f\"Base model not found: {path}\")\n",
        "    base_models.append(load_model(path, compile=False))\n",
        "\n",
        "# derive some handy constants\n",
        "NUM_CLASSES = base_models[0].output_shape[-1]\n",
        "IN_H, IN_W  = base_models[0].input_shape[1:3]\n",
        "print(f\"→ expecting {NUM_CLASSES} classes, input size {IN_H}×{IN_W}\")\n",
        "\n",
        "# ─── 3) FEATURE EXTRACTOR ───────────────────────────────────────────────────\n",
        "def get_pixel_probs(img_rs):\n",
        "    \"\"\"\n",
        "    img_rs: IN_H×IN_W×3 float32 in [0,1]\n",
        "    returns: (IN_H*IN_W, M * NUM_CLASSES) array of softmax probabilities\n",
        "    \"\"\"\n",
        "    ps = []\n",
        "    for m in base_models:\n",
        "        pm = m.predict(img_rs[None], verbose=0)[0]      # (IN_H,IN_W,NUM_CLASSES)\n",
        "        ps.append(pm.reshape(-1, NUM_CLASSES))         # (IN_H*IN_W,NUM_CLASSES)\n",
        "    return np.concatenate(ps, axis=1)                 # (IN_H*IN_W, M·C)\n",
        "\n",
        "# ─── 4) BALANCED PIXEL SAMPLING & TRAIN SET BUILDING ───────────────────────\n",
        "from collections import defaultdict\n",
        "\n",
        "IMG_DIR  = \"/content/drive/MyDrive/Project_41725/newdata/train_maskimg/images\"\n",
        "MSK_DIR  = \"/content/drive/MyDrive/Project_41725/newdata/train_maskimg/masks\"\n",
        "IMG_EXTS = (\".png\", \".jpg\", \".jpeg\")\n",
        "MSK_EXTS = (\".tif\", \".tiff\")\n",
        "\n",
        "train_imgs  = sorted(sum([list(tqdm.__wrapped__(glob := __import__('glob').glob(\n",
        "    os.path.join(IMG_DIR, f\"*{ext}\")))) for ext in IMG_EXTS], []))\n",
        "train_masks = sorted(sum([list(glob(os.path.join(MSK_DIR, f\"*{ext}\"))) for ext in MSK_EXTS], []))\n",
        "\n",
        "if len(train_imgs) != len(train_masks):\n",
        "    raise RuntimeError(\"Image/mask count mismatch!\")\n",
        "\n",
        "X_per_cls = defaultdict(list)\n",
        "y_per_cls = defaultdict(list)\n",
        "\n",
        "print(\"Sampling pixels per class…\")\n",
        "for img_path, msk_path in tqdm(zip(train_imgs, train_masks),\n",
        "                               total=len(train_imgs),\n",
        "                               desc=\"Images\"):\n",
        "    # load & prep\n",
        "    img   = cv2.imread(img_path)[..., ::-1].astype(np.float32)/255.0\n",
        "    msk   = cv2.imread(msk_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img_rs = cv2.resize(img, (IN_W, IN_H), interpolation=cv2.INTER_AREA)\n",
        "    msk_rs = cv2.resize(msk, (IN_W, IN_H),\n",
        "                        interpolation=cv2.INTER_NEAREST).ravel()\n",
        "    P      = get_pixel_probs(img_rs)  # (IN_H*IN_W, M·C)\n",
        "\n",
        "    for cls in range(NUM_CLASSES):\n",
        "        idxs = np.where(msk_rs == cls)[0]\n",
        "        if len(idxs)==0:\n",
        "            continue\n",
        "        take = np.random.choice(\n",
        "            idxs,\n",
        "            min(SAMPLES_PER_CLASS_PER_IMAGE, len(idxs)),\n",
        "            replace=False\n",
        "        )\n",
        "        X_per_cls[cls].append(P[take])\n",
        "        y_per_cls[cls].append(np.full(len(take), cls, dtype=np.int32))\n",
        "\n",
        "# stack into final X_train, y_train\n",
        "X_list, y_list = [], []\n",
        "for cls in range(NUM_CLASSES):\n",
        "    if X_per_cls[cls]:\n",
        "        X_list.append(np.vstack(X_per_cls[cls]))\n",
        "        y_list.append(np.concatenate(y_per_cls[cls]))\n",
        "\n",
        "X_train = np.vstack(X_list)\n",
        "y_train = np.concatenate(y_list)\n",
        "print(\"  → X_train:\", X_train.shape, \"y_train classes:\", np.unique(y_train))\n",
        "\n",
        "# ─── 5) TRAIN META-LEARNERS & SAVE ─────────────────────────────────────────\n",
        "print(\"Training RandomForest…\")\n",
        "rf = RandomForestClassifier(n_estimators=100,\n",
        "                            n_jobs=-1,\n",
        "                            random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training XGBoost…\")\n",
        "xgb = XGBClassifier(\n",
        "    objective=\"multi:softprob\",\n",
        "    num_class=NUM_CLASSES,\n",
        "    eval_metric=\"mlogloss\",\n",
        "    use_label_encoder=False,\n",
        "    n_jobs=4,\n",
        "    random_state=42\n",
        ")\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# save them\n",
        "rf_pth  = os.path.join(MODEL_DIR, \"rf_meta.pkl\")\n",
        "xgb_pth = os.path.join(MODEL_DIR, \"xgb_meta.ubj\")\n",
        "joblib.dump(rf, rf_pth)\n",
        "xgb.save_model(xgb_pth)\n",
        "print(f\"✅ Meta-learners saved →\\n  {rf_pth}\\n  {xgb_pth}\")\n",
        "\n",
        "# ─── 6) MANUAL SOFT-VOTING WRAPPER ──────────────────────────────────────────\n",
        "class ManualVotingClassifier(BaseEstimator):\n",
        "    def __init__(self, estimators):\n",
        "        self.models = [m for _,m in estimators]\n",
        "    def predict_proba(self, X):\n",
        "        ps = [m.predict_proba(X) for m in self.models]\n",
        "        return sum(ps)/len(ps)\n",
        "    def predict(self, X):\n",
        "        return np.argmax(self.predict_proba(X), axis=1)\n",
        "\n",
        "vc_meta = ManualVotingClassifier([\n",
        "    (\"rf\", rf),\n",
        "    (\"xgb\", xgb),\n",
        "])\n",
        "\n",
        "# ─── 7) INFERENCE FUNCTION ─────────────────────────────────────────────────\n",
        "def segment_image(img_path, out_path=\"seg.png\"):\n",
        "    if not os.path.isfile(img_path):\n",
        "        raise FileNotFoundError(img_path)\n",
        "    bgr = cv2.imread(img_path)\n",
        "    if bgr is None:\n",
        "        raise ValueError(f\"Bad image: {img_path}\")\n",
        "    rgb = bgr[..., ::-1].astype(np.float32)/255.0\n",
        "    H,W=rgb.shape[:2]\n",
        "    rs=cv2.resize(rgb,(IN_W,IN_H),cv2.INTER_AREA)\n",
        "    P = get_pixel_probs(rs)        # (IN_H*IN_W, M·C)\n",
        "    lbl = vc_meta.predict(P)       # (IN_H*IN_W,)\n",
        "    mask=lbl.reshape(IN_H,IN_W).astype(np.uint8)\n",
        "    full=cv2.resize(mask,(W,H),cv2.INTER_NEAREST)\n",
        "    cv2.imwrite(out_path, full)\n",
        "    return rgb, full\n",
        "\n",
        "# ─── 8) UPLOAD & RUN GUI ───────────────────────────────────────────────────\n",
        "print(\"▶ Upload one or more MRI slices…\")\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "    print(\"→ Segmenting\", fn)\n",
        "    orig, seg = segment_image(fn, out_path=f\"seg_{fn}\")\n",
        "    fig,axs=plt.subplots(1,2,figsize=(10,5))\n",
        "    axs[0].imshow(orig); axs[0].set_title(\"Input\"); axs[0].axis(\"off\")\n",
        "    axs[1].imshow(seg,cmap=\"gray\"); axs[1].set_title(\"Mask\"); axs[1].axis(\"off\")\n",
        "    plt.show()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── INSTALL ────────────────────────────────────────────────────────────────\n",
        "!pip install --quiet gradio opencv-python-headless pyngrok\n",
        "\n",
        "# ─── IMPORTS ────────────────────────────────────────────────────────────────\n",
        "import gradio as gr\n",
        "import cv2, os, numpy as np, joblib\n",
        "from sklearn.base import BaseEstimator\n",
        "from xgboost import XGBClassifier\n",
        "from tensorflow.keras.models import load_model\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# ─── NGROK AUTH (one-time) ───────────────────────────────────────────────────\n",
        "NGROK_AUTH_TOKEN = \"2wKvbH4ujh2zcb92IlGBTDPLbxb_3kHBmmeRAKb5LHdrErfCo\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# ─── META-LEARNERS ───────────────────────────────────────────────────────────\n",
        "MODEL_DIR = \"/content/drive/MyDrive/Project_41725/models_new\"\n",
        "xgb_meta  = XGBClassifier();  xgb_meta.load_model(os.path.join(MODEL_DIR, \"xgb_meta.model\"))\n",
        "rf_meta   = joblib.load(os.path.join(MODEL_DIR, \"rf_meta.pkl\"))\n",
        "\n",
        "class ManualVotingClassifier(BaseEstimator):\n",
        "    def __init__(self, estimators):\n",
        "        self.models = [m for _, m in estimators]\n",
        "    def predict_proba(self, X):\n",
        "        probs = [m.predict_proba(X) for m in self.models]\n",
        "        return sum(probs) / len(probs)\n",
        "    def predict(self, X):\n",
        "        return np.argmax(self.predict_proba(X), axis=1)\n",
        "\n",
        "vc_meta = ManualVotingClassifier([(\"xgb\", xgb_meta), (\"rf\", rf_meta)])\n",
        "\n",
        "# ─── BASE SEGMENTATION MODELS ────────────────────────────────────────────────\n",
        "BASE_MODEL_DIR = \"/content/drive/MyDrive/Project_41725/files\"\n",
        "MODEL_PATHS = [\n",
        "    \"UNetModified/model.h5\",\n",
        "    \"LinkNet/model.h5\",\n",
        "    \"aug_pass/model_512.h5\",\n",
        "    \"DG/model.h5\",\n",
        "    \"DG/model_256.h5\",\n",
        "]\n",
        "base_models = [\n",
        "    load_model(os.path.join(BASE_MODEL_DIR, p), compile=False)\n",
        "    for p in MODEL_PATHS\n",
        "]\n",
        "NUM_CLASSES = base_models[0].output_shape[-1]\n",
        "IN_H, IN_W  = base_models[0].input_shape[1:3]\n",
        "\n",
        "# ─── CLASS NAMES & COLORS ───────────────────────────────────────────────────\n",
        "class_names = {\n",
        "    0: \"background\",\n",
        "    1: \"glioma\",\n",
        "    2: \"mengoma\",\n",
        "    3: \"pituitary\",\n",
        "    4: \"dementia\"\n",
        "}\n",
        "palette = {\n",
        "    0: (  0,   0,   0),\n",
        "    1: (255,   0,   0),\n",
        "    2: (  0, 255,   0),\n",
        "    3: (  0,   0, 255),\n",
        "    4: (255, 255,   0)\n",
        "}\n",
        "\n",
        "# ─── FEATURE EXTRACTOR ───────────────────────────────────────────────────────\n",
        "def get_pixel_probs(img_rs):\n",
        "    feats = []\n",
        "    for m in base_models:\n",
        "        pm = m.predict(img_rs[None], verbose=0)[0]        # (IN_H,IN_W,NUM_CLASSES)\n",
        "        feats.append(pm.reshape(-1, NUM_CLASSES))         # (IN_H*IN_W, NUM_CLASSES)\n",
        "    return np.concatenate(feats, axis=1)                 # (IN_H*IN_W, M·C)\n",
        "\n",
        "# ─── SEGMENT & STATS ────────────────────────────────────────────────────────\n",
        "def segment_and_stats(img_rgb):\n",
        "    # normalize and resize\n",
        "    img_f  = img_rgb.astype(np.float32) / 255.0\n",
        "    H, W   = img_f.shape[:2]\n",
        "    img_rs = cv2.resize(img_f, (IN_W, IN_H), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # 1) get raw per-pixel ensemble probs\n",
        "    P     = get_pixel_probs(img_rs)                    # (IN_H*IN_W, M·C)\n",
        "    probs = vc_meta.predict_proba(P)                   # (IN_H*IN_W, NUM_CLASSES)\n",
        "\n",
        "    # 2) make dementia (class 4) harder to detect\n",
        "    probs[:, 4] *= 0.6\n",
        "    probs /= probs.sum(axis=1, keepdims=True)\n",
        "\n",
        "    # 3) initial low-res labels\n",
        "    lbl_rs = probs.argmax(axis=1).reshape(IN_H, IN_W).astype(np.uint8)\n",
        "\n",
        "    # 4) threshold low-confidence dementia → background\n",
        "    prob_map = probs.reshape(IN_H, IN_W, NUM_CLASSES)[..., 4]\n",
        "    lbl_rs[(lbl_rs == 4) & (prob_map < 0.5)] = 0\n",
        "\n",
        "    # 5) upsample to original size\n",
        "    mask = cv2.resize(lbl_rs, (W, H), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    # 6) colorize mask\n",
        "    color_mask = np.zeros((H, W, 3), dtype=np.uint8)\n",
        "    for cls, col in palette.items():\n",
        "        color_mask[mask == cls] = col\n",
        "\n",
        "    # 7) compute pixel distribution\n",
        "    unique, counts = np.unique(mask, return_counts=True)\n",
        "    total = mask.size\n",
        "    dist = {u: counts[i]/total*100 for i, u in enumerate(unique)}\n",
        "\n",
        "    # 8) top-2 classes\n",
        "    top2 = sorted(dist.items(), key=lambda kv: kv[1], reverse=True)[:2]\n",
        "    top2_str = \"; \".join(f\"Class {u} ({class_names[u]}): {p:.1f}%\"\n",
        "                         for u, p in top2)\n",
        "\n",
        "    # 9) full distribution text\n",
        "    dist_str = \"\\n\".join(\n",
        "        f\"{u} ({class_names[u]}): {counts[i]} px — {dist[u]:.1f}%\"\n",
        "        for i, u in enumerate(unique)\n",
        "    )\n",
        "\n",
        "    # 10) legend HTML\n",
        "    legend_html = \"<div style='display:flex; flex-wrap:wrap; gap:8px;'>\"\n",
        "    for u, name in class_names.items():\n",
        "        r, g, b = palette[u]\n",
        "        hexc = f\"#{r:02x}{g:02x}{b:02x}\"\n",
        "        legend_html += (\n",
        "            f\"<div style='display:flex; align-items:center; gap:4px;'>\"\n",
        "              f\"<div style='width:16px; height:16px; background:{hexc}; border:1px solid #333;'></div>\"\n",
        "              f\"<span>Class {u}: {name}</span>\"\n",
        "            f\"</div>\"\n",
        "        )\n",
        "    legend_html += \"</div>\"\n",
        "\n",
        "    return top2_str, color_mask, dist_str, legend_html\n",
        "\n",
        "# ─── GRADIO + NGROK SETUP ───────────────────────────────────────────────────\n",
        "app = gr.Blocks(css=\"\"\"\n",
        "    body { background: #f0f2f5; }\n",
        "    .gradio-container { max-width: 800px; margin: auto; padding: 1em; }\n",
        "\"\"\")\n",
        "\n",
        "with app:\n",
        "    gr.Markdown(\"## 🧠 Brain-Tumor Segmentation Ensemble\")\n",
        "    with gr.Row():\n",
        "        inp    = gr.Image(type=\"numpy\", label=\"Upload MRI (RGB)\")\n",
        "        out1   = gr.Textbox(label=\"🏆 Top-2 Classes\", interactive=False)\n",
        "    with gr.Row():\n",
        "        out2   = gr.Image(type=\"numpy\", label=\"Segmentation (Color)\")\n",
        "    with gr.Row():\n",
        "        out3   = gr.Textbox(label=\"📊 Distribution\", interactive=False)\n",
        "        legend = gr.HTML(label=\"Legend\")\n",
        "    btn = gr.Button(\"Segment\", variant=\"primary\")\n",
        "    btn.click(fn=segment_and_stats,\n",
        "              inputs=inp,\n",
        "              outputs=[out1, out2, out3, legend])\n",
        "\n",
        "# create ngrok tunnel & launch\n",
        "public_url = ngrok.connect(7860)\n",
        "print(\"▶️ Public URL:\", public_url)\n",
        "app.launch(server_name=\"0.0.0.0\", server_port=7860, share=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "EUGek-qxUWCF",
        "outputId": "1413f70c-ed45-4b72-92e6-ace2ac37eae3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️ Public URL: NgrokTunnel: \"https://6414-35-194-174-49.ngrok-free.app\" -> \"http://localhost:7860\"\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02b49f1853ae4fc5a002efdf857880d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_484314ce9f5b40f7be3553b2cb8e3815",
            "placeholder": "​",
            "style": "IPY_MODEL_eaf0423fbf95484f8fd667d5de6c7074",
            "value": "Base models: 100%"
          }
        },
        "03e095832471456ebab0c5cde3e9dc20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae6d7d9bfc5f485893a76e9325eb4d4c",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d6717f1d4d0458398904d280bc2eb05",
            "value": 300
          }
        },
        "0dfcb531c25249538b40825b885fcba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b01de9444583459cae93cf6ba1e599c0",
            "placeholder": "​",
            "style": "IPY_MODEL_48fa5a4d2e3247779371a16e4f65888d",
            "value": " 5/5 [00:12&lt;00:00,  3.07s/it]"
          }
        },
        "1539011ac6d749c8a1a33938afa590a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18421ab1de0949eb94e40874cf8bcb90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26b8a444923841db94dd5ff0ba98af7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a08480b8bd1641aba2db6cc0d7199b9c",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9c83b29ba794b10b287fce2c792a58b",
            "value": 5
          }
        },
        "46bb0266594b449ca9dbb64c88ef09cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "484314ce9f5b40f7be3553b2cb8e3815": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48fa5a4d2e3247779371a16e4f65888d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49aaebcaacb84e04aef4c74346ef69cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d6717f1d4d0458398904d280bc2eb05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f31a6cee417452683c0d3460fc14c90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53411b6efebc4352b4472b6c9008d2d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eeadaaab17774c18a31ada8bc08e1bcb",
              "IPY_MODEL_03e095832471456ebab0c5cde3e9dc20",
              "IPY_MODEL_6abf5be6d8c84331a0c390cc4c529e50"
            ],
            "layout": "IPY_MODEL_46bb0266594b449ca9dbb64c88ef09cb"
          }
        },
        "6abf5be6d8c84331a0c390cc4c529e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49aaebcaacb84e04aef4c74346ef69cb",
            "placeholder": "​",
            "style": "IPY_MODEL_1539011ac6d749c8a1a33938afa590a6",
            "value": " 300/300 [03:14&lt;00:00,  1.99it/s]"
          }
        },
        "a08480b8bd1641aba2db6cc0d7199b9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9c83b29ba794b10b287fce2c792a58b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae6d7d9bfc5f485893a76e9325eb4d4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b01de9444583459cae93cf6ba1e599c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5f25eb2206140178120b4d5ce7ac53c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea82f162305b4793a7737438ab034dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02b49f1853ae4fc5a002efdf857880d2",
              "IPY_MODEL_26b8a444923841db94dd5ff0ba98af7a",
              "IPY_MODEL_0dfcb531c25249538b40825b885fcba6"
            ],
            "layout": "IPY_MODEL_4f31a6cee417452683c0d3460fc14c90"
          }
        },
        "eaf0423fbf95484f8fd667d5de6c7074": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eeadaaab17774c18a31ada8bc08e1bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5f25eb2206140178120b4d5ce7ac53c",
            "placeholder": "​",
            "style": "IPY_MODEL_18421ab1de0949eb94e40874cf8bcb90",
            "value": "Images: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}